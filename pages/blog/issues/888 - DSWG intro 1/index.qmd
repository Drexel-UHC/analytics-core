---
title: "Data Science Working Group: Hello"
subtitle: 'Introduction to group vision, tooling and next steps.'
author: 
  - name: Usama Bilal
    orcid: 0000-0002-9868-7773
  - name: Ran Li
    orcid: 0000-0002-4699-4755
date: "2023-07-06"
format:
  revealjs:
    theme: default
    self-contained: true 
editor: visual
---

## Overview {.smaller}

-   Big Picture Vision
-   Toolkit
-   Integration

## Big Picture Vision {.smaller}

![](images/P20%20Conceptual%20+%20Platform%20Schematics%20V2%20(3)-01.png){fig-align="center"}

## Context {.smaller}

-   The DSWG was created to around a directive to think about projects at a 'system' level from raw data to deliverable to researchers, policy-makers and community members.

-   Research is 80% data cleaning (**Access**) and 20% actual research (**Understand**)

-   Research and data are much more valuable if they can be **communicated** to stakeholders (other researchers, policy makers, community).

-   We aim to sustain a workflow that is built on **software engineering best practices** and develop students/staff that to provide this as service to projects both internal and external to UHC.

## Toolkit {.smaller}

1.  Principles
    -   FAIR
    -   Keep abreast of industry trends
    -   Tool agnostic
2.  Access
    -   Grammar of data manipulation
    -   Data warehousing
3.  Communicate
    -   GitHub
    -   Packages
    -   Literate Programming
    -   Dashboards
    -   Web development

## 1.1 FAIR

-   FAIR: Findable, Accessible, Interoperable, Reusable
-   Code: web documentation, version control, packaging
-   Data: metadata, lineage, versioning, web documentation
-   Research: findable, accessible stories told to target audiences.

## 1.2 Innovation (pt 1) {.smaller}

-   NIH create an [Office of Data Science Strategy](https://datascience.nih.gov/)
    -   findability, interconnectivity, and interoperability of NIH-funded biomedical data sets and resources
    -   integration of existing data management tools and development of new ones
    -   universalization of innovative algorithms and tools created by academic scientists into enterprise-ready resources that meet industry standards of ease of use and efficiency of operation
    -   growing costs of data management.

## 1.2 Innovation (pt 2) {.smaller}

-   Pharma: [Roche](https://www.youtube.com/watch?v=nqJsLSLd39A&ab_channel=PositPBC) and big pharma to default to R as primay language for new trials
-   Modern Data warehousing: [helping data teams work like software engineers with DBT](https://github.com/dbt-labs)
-   Full stack Component based Javascript frameworks. React.js, [Next.js](https://nextjs.org/), [Svelte.js](https://svelte.dev/)
-   Journalism embrace of open source Javascript for story telling (e.g. [Rueters graphics patterns](https://reuters-graphics.github.io/example_svelte-graph-patterns/)
-   Web hosting is free (Azure static web app, GH pages, Netlify, AWS amplify)
-   Serverless infrastructure is cheap and easy (AWS lambda, Azure function apps)

## 1.3 Language Agnostic {.smaller}

-   Move away from having one solution for how we do promgramming
-   The flexibility to move towards the best tool for solving problems is paramount
-   So tools we are using now are not the destination. Its part of a journey that allows us to constantly shift to what the best tool is best for us in the future.
-   Embrace open source culture of collaboratively building solutions as software developers rather than software consumers.

## 2.1 Dplyr - Grammar of data manipulation {.smaller .scrollable}

```{r}
library(dplyr)
library(dbplyr)
library(arrow)
library(reactable)

penguins_data_url = 'https://gist.githubusercontent.com/slopp/ce3b90b9168f2f921784de84fa445651/raw/4ecf3041f0ed4913e7c230758733948bc561f434/penguins.csv'
data = read.csv(penguins_data_url)
# data %>% arrow::write_parquet('penguins.parquet')

data %>% reactable(defaultPageSize  = 4, compact = T)
head(data)
```

## 2.1 Dplyr - flat files (.csv) {.smaller .scrollable}

::: panel-tabset
## Semantics

> Research Question:Calculate ratio of bill length to depth then calculate rank by species. Return a table whose rows are arranged in order by species and contiaining only relevant columns.

1.  Use penguins as the input data
2.  Group by species
3.  Calculate bill length depth ratio
4.  Arrange rows based on rank
5.  Select columns: species, rank, ratio
6.  Calculate rank of ratio_bill

## .csv

``` {.r code-line-numbers="|1-2|2|3|4|5|6"}
data = read.csv(penguins_data_url)
data %>%
  group_by(species) %>%
  mutate(ratio_bill = bill_length_mm/bill_depth_mm) %>% 
  select(species, ratio_bill ) %>% 
  mutate(rank = rank(desc(ratio_bill ))) %>% 
  arrange(rank)
```

```{r }
## Import data
data = read.csv(penguins_data_url)
  
## Wrangling (dplyr)
data %>%
  group_by(species) %>%
  mutate(ratio_bill = bill_length_mm/bill_depth_mm) %>% 
  select(species, ratio_bill ) %>% 
  mutate(rank = rank(desc(ratio_bill ))) %>% 
  arrange(rank)
```
:::

## 2.1 Dplyr - flat files (.csv) {.smaller .scrollable}

::: panel-tabset
## Semantics

> Research Question:Calculate ratio of bill length to depth then calculate rank by species. Return a table whose rows are arranged in order by species and contiaining only relevant columns.

1.  Use penguins as the input data
2.  Group by species
3.  Calculate bill length depth ratio
4.  Arrange rows based on rank
5.  Select columns: species, rank, ratio
6.  Calculate rank of ratio_bill

## Dplyr + .csv

``` {.r code-line-numbers="|6|5|4|3|2|1"}
data %>%
  group_by(species) %>%
  mutate(ratio_bill = bill_length_mm/bill_depth_mm) %>% 
  select(species, ratio_bill ) %>% 
  mutate(rank = rank(desc(ratio_bill ))) %>% 
  arrange(rank)
```

```{r }
## Import data
data = read.csv(penguins_data_url)
  
## Wrangling (dplyr)
data %>%
  group_by(species) %>%
  mutate(ratio_bill = bill_length_mm/bill_depth_mm) %>% 
  select(species, ratio_bill ) %>% 
  mutate(rank = rank(desc(ratio_bill ))) %>% 
  arrange(rank)
```
:::

## 2.1 Dplyr - Databases (e.g. SQLite) {.smaller .scrollable}

::: panel-tabset
## Semantics

> Research Question:Calculate ratio of bill length to depth then calculate rank by species. Return a table whose rows are arranged in order by species and contiaining only relevant columns.

1.  Use penguins as the input data
2.  Group by species
3.  Calculate bill length depth ratio
4.  Arrange rows based on rank
5.  Select columns: species, rank, ratio
6.  Calculate rank of ratio_bill

## Dplyr + Database

``` {.r code-line-numbers="|1-2|3|4|5|6|7"}
database  <- memdb_frame(data)
query = database %>%
  group_by(species) %>%
  mutate(ratio_bill = bill_length_mm/bill_depth_mm) %>% 
  select(species, ratio_bill ) %>% 
  mutate(rank = rank(desc(ratio_bill ))) %>% 
  arrange(rank)

query %>% collect()
```

```{r}
  ## Connect to database
  database  <- memdb_frame(data)
  
  ## Wrangling (dplyr)
  query = database %>%
    group_by(species) %>%
    mutate(ratio_bill = bill_length_mm/bill_depth_mm) %>% 
    select(species, ratio_bill ) %>% 
    mutate(rank = rank(desc(ratio_bill ))) %>% 
    arrange(rank)
  query %>%  collect()
```

## Dplyr + SQL

``` r
query %>% show_query()
```

```{r}
query %>% show_query()
```
:::

## 2.1 Dplyr - Columnar storage (e.g. Parquet) {.smaller .scrollable}

::: panel-tabset
## Semantics

> Research Question:Calculate ratio of bill length to depth then calculate rank by species. Return a table whose rows are arranged in order by species and contiaining only relevant columns.

1.  Use penguins as the input data
2.  Group by species
3.  Calculate bill length depth ratio
4.  Arrange rows based on rank
5.  Select columns: species, rank, ratio
6.  Calculate rank of ratio_bill

## Dplyr + parquet

``` {.r code-line-numbers="|1-2|3|4|5|6|7"}
  dataset = open_dataset('penguins.parquet')
  dataset %>%
    group_by(species) %>%
    mutate(ratio_bill = bill_length_mm/bill_depth_mm) %>% 
    select(species, ratio_bill ) %>% 
    collect() %>% 
    mutate(rank = rank(desc(ratio_bill ))) %>% 
    arrange(rank)
```

```{r}
  ## Open Dataset
  dataset = open_dataset('penguins.parquet')

  ## Form query
  dataset %>%
    group_by(species) %>%
    mutate(ratio_bill = bill_length_mm/bill_depth_mm) %>% 
    select(species, ratio_bill ) %>% 
    collect() %>% 
    mutate(rank = rank(desc(ratio_bill ))) %>% 
    arrange(rank)
```
:::

## 1. Dplyr - multilingual {.smaller .scrollable}

-   R: [dplyr](https://dplyr.tidyverse.org/), [dbplyr](https://dbplyr.tidyverse.org/)
-   JavaScript: [tidy.js](https://pbeshai.github.io/tidy/)
-   Python: [Polars](https://tidypolars.readthedocs.io/en/latest/#general-syntax)
-   SQL: [PRQL](https://prql-lang.org/)

## 1. Dplyr - Summary {.smaller .scrollable}

-   Foundation of R&D is data manipulation
-   Dplyr work flow focuses on semantics and not syntax. meaning easy onboarding.
-   It is expressive: meaning complex wrangling logic in less code = faster development = less maintenance
-   It is powerful: works with databases and modern data formats.
-   Skills translatable to other languages
-   

## 2.2 Data Warehousing {.smaller .scrollable}

-   While dplyr is great for working on specific tasks and projects (e.g. operationalizing a dataset). It does not have the tools required for data warehousing.
-   Data modeling is like designing the blueprint for a house, but instead of rooms and doors, you're planning where to store different types of information and how they connect to each other.
-   It is a key tool to implementing FAIR at an organizaiton level, in order to reduce repeated work, handle big data, document data lineage, and make outputs accessible.
-   DBT:
    -   HCUP: https://drexel-uhc.github.io/hcup-dbt/
    -   DBT training: https://drexel-uhc.github.io/analytics-corner/pages/manuals/dbt/overview.html

## 3.1 Communicate Software (GitHub) {.smaller .scrollable}

-   GitHub is a online version control and project management platform
    -   developer features (git, CI/DI, virtual machines)
    -   project management features (issues, discussions, projects, teams, emails)
    -   website host
    -   package host
    -   [Example of collaboration](https://drexel-uhc.github.io/analytics-corner/pages/manuals/git-github/case-study-project-transition-management.html)
-   Resources:
    -   [UHC Github Organization](https://github.com/Drexel-UHC)
    -   [DSWG GitHub Manual](https://drexel-uhc.github.io/analytics-corner/pages/manuals/git-github/overview.html)
    -   [NIH GitHub Resource Center](https://github.nih.gov/)
-   Version control is fundamental to reproducibility and effective collaboration.

## 3.2 Reuse Software: R Packages {.smaller .scrollable}

-   R packages are a mature set of best practices, guidelines how how to write R code and the tools to share them.
-   This has led to very influential opens source software ecoystems that are comparable or surpass enterprise solutions.
    -   tidycensus
    -   tidyverse
-   Instead email code and writing .doc. R packages give us a easy way to develop custom solutions for our problems, document them and share them.
-   A local package ecosystem will help automate so many tasks and they also can be published to increase the impact of the work we do.
-   Examples from the DSWG
    -   [findSVI](https://heli-xu.github.io/findSVI/)
    -   [shinyUHC](https://drexel-uhc.github.io/shinyUHC/)
    -   [tidySALURBAL](https://drexel-uhc.github.io/tidySALURBAL/)
    -   [HERcrosswalks](https://github.com/her43/HERcrosswalks)

## 3.3 Communicate results: Quarto {.smaller .scrollable}

-   Literate Programming is the idea of being able to notebook with text (markdown) and code (R,Python, Julia, Javascript).
-   [Knitr](https://github.com/yihui/knitr) is an engine that combines R + .md
-   [Jupyter](https://jupyter.org/) is an engine that combines Python + .md
-   [Quarto](https://quarto.org/) builds onto over various language engines (Knitr, Jupyter) and binds outputs to various formats (web slides, ppt, word, html, websites, books, blogs)
-   Allows analysts to rapid share their work in accessible formats.
-   It saves time: no copying into word or ptt. single source of code -\> multiple outputs.
-   Examples:
    -   [DSWG page](https://drexel-uhc.github.io/analytics-corner/)
    -   [BCHC COVID Inequities Website/Blog](https://www.covid-inequities.info/)
    -   [SALURBAL renovation page](https://drexel-uhc.github.io/salurbal-fair-renovations/)
    -   [R and Python Data Cheat Sheet](https://ran-codes.github.io/python-rstudio/)
    -   [External: Royal Statiscal Society](https://realworlddatascience.net/)

## 3.4 Communicate analytic results: Dashboards {.smaller .scrollable}

-   [Shiny](https://shiny.posit.co/) is a multi-lingual (R, Python) tool for building web applications without needing any web development skills

-   Interactivity is a must as data becomes more complex and higer volume. A dashboard is much more accessible that a 200 page PDF to communicate analytic results.

-   Gives analysts the ability to extend their R/Python expertise by adding interactivity.

-   The UHC already has infrastructure to deploy Shiny applications with just a click of a button.

-   Easy to learn and fast to develop. Examples

    -   [UHC-PDPH Cancer app 2](https://drexel-uhc.shinyapps.io/cancer_in_philadelphia_neighborhoods/)
    -   [SALURBAL Heat Manuscript](https://drexel-uhc.shinyapps.io/MS85/)
    -   [BCHC COVID inequities](https://drexel-uhc.shinyapps.io/bchc_covid19/)
    -   [UHC Student's dashboard](https://drexel-uhc.shinyapps.io/Congress_Mortality/)

## 3.5 Communicate results: Web content {.smaller .scrollable}

-   Why not dashbaords:
    -   server based which requires infrastructure and compute costs
    -   cold starts for consumption plans are not feasible for public facing content
    -   great for communicating analytic results but not telling stories. policy makers and community members don't have time to click around
    -   Dashboards need a server to run (R/Python) in addition to user brower to run (JS)
-   We adopt indsutry trend to move everything to JS with modern JS frameworks: React.js, [Next.js](https://nextjs.org/), [Svelte.js](https://svelte.dev/)
    -   Low cost
    -   Highly flexible
    -   Inter operable with many existing service API's
    -   Harness open source JS codebases
    -   Utilize server less computing (lambda/azure-functions) for any computations
-   Examples:
    -   [SALURBAL Data Portal](https://data.lacurbanhealth.org/).

    -   Digital journalism

        -   idea: [Digital Journalism for urban health](https://drexel-uhc.github.io/analytics-corner/pages/blog/issues/888%20-%20Scrollies/)

        -   example: [The Pudding repository](https://github.com/the-pudding/eu-regions)

        -   adaptation: [MAUP Philadelphia](https://mockup-uhc-graphics-maup.netlify.app/)

## Toolkit Recap {.smaller}

1.  Principles
    -   FAIR
    -   Keep abreast of industry trends
    -   Tool agnostic
2.  Access
    -   Grammar of data manipulation
    -   Data warehousing
3.  Communicate
    -   GitHub
    -   Packages
    -   Literate Programming
    -   Dashboards
    -   Web development

## It takes a village

![](images/village.JPG){fig-align="center"}

## 4. Integration with RDC

-   Data/backend \*\*
-   statistics
-   front-end
-   training/Data-Team \*\*

## 4. Integration with Other Cores

-   Training
    -   Summer Institutes FAIR or DS course
-   Policy
    -   front-end
-   Community Engagement
    -   front-end

## Appendix: Rollout

![](images/rollout.JPG){fig-align="center"}
